{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more libraries so that it processes faster\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.model_selection import train_test_split as tts, cross_val_score as cvs\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up sessions to improve performance\n",
    "\n",
    "def reset_keras():\n",
    "  sess = get_session()\n",
    "  clear_session()\n",
    "  sess.close()\n",
    "  sess = get_session()\n",
    "\n",
    "def store_CPU(x):\n",
    "  with tf.device('/CPU:0'):\n",
    "      x=x\n",
    "      reset_keras()\n",
    "      gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in data and convert it for the purposes of of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define input and output variables from training data\n",
    "\n",
    "random_seed = 1234\n",
    "\n",
    "X = train.drop('label', axis = 1).astype('float32')\n",
    "y = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforma the data\n",
    "#normalize X - pixels can only be between 0 and 255\n",
    "\n",
    "X = X/255\n",
    "\n",
    "#define labels and then one-hot encode\n",
    "y = to_categorical(y, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get total inputs and classes\n",
    "\n",
    "n_input = X.shape[1]\n",
    "n_classes = y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model using training/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a54838\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a54838\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Define Model, 20 nodes and 1 hidden layer\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=n_input, activation='relu', kernel_initializer='normal'))\n",
    "model.add(Dense(20, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(n_classes, activation = 'softmax', kernel_initializer = 'normal'))\n",
    "\n",
    "sgd = SGD(lr = 0.01)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = sgd,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a54838\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a54838\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      "33600/33600 [==============================] - 7s 198us/step - loss: 2.2736 - acc: 0.2019 - val_loss: 2.2306 - val_acc: 0.2900\n",
      "Epoch 2/20\n",
      "33600/33600 [==============================] - 5s 141us/step - loss: 2.1281 - acc: 0.3769 - val_loss: 1.9781 - val_acc: 0.4395\n",
      "Epoch 3/20\n",
      "33600/33600 [==============================] - 7s 211us/step - loss: 1.7202 - acc: 0.5276 - val_loss: 1.4358 - val_acc: 0.6511\n",
      "Epoch 4/20\n",
      "33600/33600 [==============================] - 5s 159us/step - loss: 1.2043 - acc: 0.6987 - val_loss: 1.0132 - val_acc: 0.7365\n",
      "Epoch 5/20\n",
      "33600/33600 [==============================] - 6s 170us/step - loss: 0.8881 - acc: 0.7605 - val_loss: 0.7838 - val_acc: 0.7837\n",
      "Epoch 6/20\n",
      "33600/33600 [==============================] - 7s 214us/step - loss: 0.7154 - acc: 0.8004 - val_loss: 0.6591 - val_acc: 0.8135\n",
      "Epoch 7/20\n",
      "33600/33600 [==============================] - 7s 202us/step - loss: 0.6176 - acc: 0.8236 - val_loss: 0.5884 - val_acc: 0.8329\n",
      "Epoch 8/20\n",
      "33600/33600 [==============================] - 8s 226us/step - loss: 0.5564 - acc: 0.8387 - val_loss: 0.5400 - val_acc: 0.8419\n",
      "Epoch 9/20\n",
      "33600/33600 [==============================] - 8s 234us/step - loss: 0.5141 - acc: 0.8499 - val_loss: 0.5064 - val_acc: 0.8530\n",
      "Epoch 10/20\n",
      "33600/33600 [==============================] - 7s 213us/step - loss: 0.4822 - acc: 0.8600 - val_loss: 0.4804 - val_acc: 0.8607\n",
      "Epoch 11/20\n",
      "33600/33600 [==============================] - 6s 182us/step - loss: 0.4567 - acc: 0.8679 - val_loss: 0.4597 - val_acc: 0.8658\n",
      "Epoch 12/20\n",
      "33600/33600 [==============================] - 7s 211us/step - loss: 0.4360 - acc: 0.8742 - val_loss: 0.4433 - val_acc: 0.8707\n",
      "Epoch 13/20\n",
      "33600/33600 [==============================] - 7s 205us/step - loss: 0.4183 - acc: 0.8790 - val_loss: 0.4278 - val_acc: 0.8751\n",
      "Epoch 14/20\n",
      "33600/33600 [==============================] - 8s 231us/step - loss: 0.4027 - acc: 0.8839 - val_loss: 0.4151 - val_acc: 0.8795\n",
      "Epoch 15/20\n",
      "33600/33600 [==============================] - 7s 221us/step - loss: 0.3894 - acc: 0.8876 - val_loss: 0.4031 - val_acc: 0.8817\n",
      "Epoch 16/20\n",
      "33600/33600 [==============================] - 9s 258us/step - loss: 0.3774 - acc: 0.8909 - val_loss: 0.3922 - val_acc: 0.8846\n",
      "Epoch 17/20\n",
      "33600/33600 [==============================] - 8s 240us/step - loss: 0.3668 - acc: 0.8940 - val_loss: 0.3827 - val_acc: 0.8868\n",
      "Epoch 18/20\n",
      "33600/33600 [==============================] - 7s 197us/step - loss: 0.3574 - acc: 0.8969 - val_loss: 0.3749 - val_acc: 0.8908\n",
      "Epoch 19/20\n",
      "33600/33600 [==============================] - 5s 149us/step - loss: 0.3489 - acc: 0.8992 - val_loss: 0.3671 - val_acc: 0.8926\n",
      "Epoch 20/20\n",
      "33600/33600 [==============================] - 6s 171us/step - loss: 0.3411 - acc: 0.9018 - val_loss: 0.3608 - val_acc: 0.8952\n"
     ]
    }
   ],
   "source": [
    "#fit model\n",
    "start = timer()\n",
    "Xtrain, Xtest, ytrain, ytest = tts(X, y, test_size = .2, random_state = random_seed)\n",
    "train = model.fit(Xtrain, ytrain, validation_data = (Xtest, ytest), epochs = 20, batch_size = 200, verbose = 1)\n",
    "end = timer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train: 136.468\n",
      "Training Scores: Accuracy = 0.903, Loss = 0.336\n",
      "Test Scores: Accuracy = 0.895, Loss = 0.361\n"
     ]
    }
   ],
   "source": [
    "#test model scores\n",
    "train_score = model.evaluate(Xtrain, ytrain, verbose = 0)\n",
    "test_score = model.evaluate(Xtest, ytest, verbose = 0)\n",
    "print('Time to train: {:.3f}'.format(end-start))\n",
    "print('Training Scores: Accuracy = {:.3f}, Loss = {:.3f}'.format(train_score[1], train_score[0]))\n",
    "print('Test Scores: Accuracy = {:.3f}, Loss = {:.3f}'.format(test_score[1], test_score[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a class that handles all of the work for each version of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a class that will produce all models\n",
    "\n",
    "class Network:\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def model(self, layers, nodes, optimizer, lr):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(nodes, input_dim=n_input, activation='relu', kernel_initializer='normal'))\n",
    "        for _ in range(1,layers+1):\n",
    "            model.add(Dense(nodes, activation='relu', kernel_initializer='normal'))\n",
    "        model.add(Dense(n_classes, activation = 'softmax', kernel_initializer = 'normal'))\n",
    "        optimizer = optimizer(lr = lr)\n",
    "        model.compile(loss = 'categorical_crossentropy',\n",
    "                     optimizer = optimizer,\n",
    "                     metrics=['accuracy'])\n",
    "        print('Parameters: Layers = {:2}, Nodes = {:2}'.format(layers, nodes))\n",
    "        return model\n",
    "    \n",
    "    def fit (self, model, x, y):\n",
    "        start = timer()\n",
    "        train = model.fit(x, y, epochs = 20, batch_size = 200, verbose = 0)\n",
    "        end = timer()\n",
    "        train_score = model.evaluate(Xtrain, ytrain, verbose = 0)\n",
    "        print('Time to train: {:.3f}'.format(end-start))\n",
    "        print('Training Scores: Accuracy = {:.3f}, Loss = {:.3f}'.format(train_score[1], train_score[0]))\n",
    "\n",
    "    def kaggle (self, model, filename, X):\n",
    "        pred = model.predict_classes(X)\n",
    "        imageid = [int(i) for i in range(1,len(pred)+1)]\n",
    "        file = pd.DataFrame({'ImageID': imageid,\n",
    "                            'Label': pred})                        \n",
    "        file.to_csv(filename, index = False, header = True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define class\n",
    "run_one = Network(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: Layers =  2, Nodes = 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2f48d4a8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set model parameters\n",
    "run_one.model(2, 20, SGD, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train: 122.703\n",
      "Training Scores: Accuracy = 0.959, Loss = 0.143\n"
     ]
    }
   ],
   "source": [
    "#fit model\n",
    "run_one.fit(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce output\n",
    "run_one.kaggle(model, 'NN_Submission_1.csv', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define class\n",
    "run_two = Network(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: Layers =  5, Nodes = 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x28f966d8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set model parameters\n",
    "run_two.model(5,20, SGD, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train: 80.939\n",
      "Training Scores: Accuracy = 0.963, Loss = 0.131\n"
     ]
    }
   ],
   "source": [
    "#fit model\n",
    "run_two.fit(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce output\n",
    "run_two.kaggle(model, 'NN_Submission_2.csv', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define class\n",
    "run_three = Network(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: Layers =  2, Nodes = 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x290c7fd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set model parameters\n",
    "run_three.model(2, 40, SGD, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train: 136.269\n",
      "Training Scores: Accuracy = 0.965, Loss = 0.121\n"
     ]
    }
   ],
   "source": [
    "#fit model\n",
    "run_three.fit(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce output\n",
    "run_three.kaggle(model, 'NN_Submission_3.csv', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define class\n",
    "run_four = Network(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: Layers =  5, Nodes = 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x29224668>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set model parameters\n",
    "run_four.model(5, 40, SGD, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train: 139.961\n",
      "Training Scores: Accuracy = 0.968, Loss = 0.112\n"
     ]
    }
   ],
   "source": [
    "#fit model\n",
    "run_four.fit(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce output\n",
    "run_four.kaggle(model, 'NN_Submission_4.csv', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
